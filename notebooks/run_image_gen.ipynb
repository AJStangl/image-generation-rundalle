{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import ruclip\n",
    "from rudalle import get_rudalle_model, get_vae, get_tokenizer, get_realesrgan\n",
    "from rudalle.pipelines import generate_images, show, cherry_pick_by_ruclip, super_resolution\n",
    "from rudalle.utils import seed_everything\n",
    "import torch\n",
    "from translatepy import Translate\n",
    "print(\"Imports Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.num_picturs = 1\n",
    "        self.checkpoint_path = '/data/workspace/checkpoints'\n",
    "        self.model_name = 'local_model'\n",
    "        self.output_image_path = '/data/workspace/output_images'\n",
    "        self.rudalle_cache_dir = '/data/workspace/rudalle'\n",
    "\n",
    "def save_pil_images(pil_images) -> [str]:\n",
    "    args = Args()\n",
    "    out = []\n",
    "    current_time = datetime.now().strftime('%y-%m-%d_%H-%M-%S')\n",
    "    for k in range(len(pil_images)):\n",
    "        output_name = f\"lg_{k}_{current_time}.png\"\n",
    "        out_file_path = os.path.join(args.output_image_path, output_name)\n",
    "        pil_images[k].save(out_file_path)\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_generation_args = Args()\n",
    "\n",
    "translation_engine = Translate()\n",
    "\n",
    "# Prepare model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = get_rudalle_model('Malevich', pretrained=True, fp16=True, device=device, cache_dir=model_generation_args.rudalle_cache_dir)\n",
    "\n",
    "vae = get_vae(dwt=True).to(device)\n",
    "\n",
    "model_path = f\"{model_generation_args.checkpoint_path}/{model_generation_args.model_name}_dalle_last.pt\"\n",
    "# model_path = os.path.join(model_generation_args.checkpoint_path, f\"{model_generation_args.model_name}_dalle_last.pt\")\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "tokenizer = get_tokenizer()\n",
    "\n",
    "realesrgan = get_realesrgan('x2', device=device)\n",
    "\n",
    "clip, processor = ruclip.load('ruclip-vit-base-patch32-384', device=device)\n",
    "\n",
    "clip_predictor = ruclip.Predictor(clip, processor, device, bs=8)\n",
    "\n",
    "print(\":: Model Initialized\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seed_everything(42)\n",
    "\n",
    "text_input = 'A happy couple'\n",
    "print(f\"Original Text: {text_input}\")\n",
    "\n",
    "# text = translation_engine.translate(text_input, \"ru\").result\n",
    "text = text_input\n",
    "print(f\"Translated Text: {text}\")\n",
    "\n",
    "pil_images = []\n",
    "scores = []\n",
    "model_generation_args.num_picturs = 1\n",
    "\n",
    "for top_k, top_p, images_num in [\n",
    "    (2048, 0.995, model_generation_args.num_picturs),\n",
    "]:\n",
    "    _pil_images, _scores = generate_images(text, tokenizer, model, vae, top_k=top_k, images_num=images_num, bs=8, top_p=top_p)\n",
    "    pil_images += _pil_images\n",
    "    scores += _scores\n",
    "\n",
    "print(\":: Image Generation Complete\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show(pil_images)\n",
    "\n",
    "top_images, clip_scores = cherry_pick_by_ruclip(pil_images, text, clip_predictor, count=model_generation_args.num_picturs)\n",
    "show(top_images, model_generation_args.num_picturs)\n",
    "\n",
    "sr_images = super_resolution(top_images, realesrgan)\n",
    "\n",
    "show(sr_images, model_generation_args.num_picturs)\n",
    "\n",
    "out_paths = save_pil_images(sr_images)\n",
    "\n",
    "print(f\":: Images Saved To {out_paths}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}